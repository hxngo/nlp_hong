[
  {
    "video_id": "qppV3n3YlF8?si=WSsUmp_5ONT0G4DW",
    "title": "RAG Explained",
    "content": "so imagine you're a journalist and you want to write an article on a specific topic now you have a pretty good general idea about this topic but you'd like to do some more research so you go to your local library right now this library has thousands of books on multiple different topics but how do you know as the journalist which books are relevant for your topic well you go to the librarian now the librarian is the expert on what books contain which information in the library so our journalist queries the librarian to uh retrieve uh books on certain topics and the librarian uh produces those books and provides them back to the journalist now the librarian isn't the expert on writing the article and the journalist isn't the expert on finding the most upto-date and relevant information but with the combination of the two we can get the job done love this sounds like a lot like the process of rag or retrieval augmented generation where large language models call on Vector databases to provide key sources of data and information to answer a question H I'm not seeing the connection can you help me understand a little bit better sure so we have a user in your scenario it's that journalist and they have a question so what types of questions would you want to ask right maybe we can make this more of a business context yeah so let's say this is a business analyst and let's say they want to ask um what was Revenue in q1 from customers in the Northeast region right so that's your prompt okay so a couple questions on that user does it have to be a person or could it be something else too yeah so this doesn't necessarily have to be a user it could be a bot or it could be another application even the question that we're talking about what was our Revenue in q1 from the Northeast you know the first part of that question it's pretty easy for you know a general llm to understand right what was our Revenue but it's that second part in q1 from customers in the Northeast that's not something that lln are trained on right it's very specific to our business and it changes over time so we have to treat those separately so how do we how do we uh manage that part of the request exactly you'll need multiple different sources of data potentially to answer a specific question right whether that's maybe a PDF or another business application or maybe some some images whatever that question is we need the appropriate data in order to provide the answer back what technology uh allows us to aggregate that data uh and use it for our llm yeah so we can take this data and we can put it into what we call a vector database a vector database is a mathematical representation of structured and unstructured data similar to what we might see in an array gotcha and and these arrays are uh better suited or easier to understand for machine learning or generative AI models versus just that uh underlying unstructured data exactly we query our Vector database right and we get back an embedding that uh includes uh the the relevant data for which uh we're prompting and then we includeed back into the original prompt right yeah exactly that feeds back into the prompt and then once we're at this point we move over to the other side of the equation which is the large language model gotcha so that that prompt that includes the vector embeddings now are fed into the large language model which then produces the output with the answer to our original question with sourced upto-date and accurate data exactly and that's a crucial aspect of it as new data comes into this Vector database or things that are updated back to your relevant question around performance in q1 as new data comes in those embeddings are updated ated so when that question's asked a second time we have more relevant data in order to provide back to the llm who then generates the output and the answer okay very cool so Sean this sounds a lot like my original analogy there with the librarian and our journalist right so the journalist trusts that the information in the library is accurate and correct now one of the challenges that I see is when I'm talking to Enterprise customers is they're concerned about deploying this kind of techn techology into customer facing business critical applications so if they're building applications taking customer orders processing refunds they're worried that uh uh these kinds of Technologies can produce hallucinations or inaccurate results right or perpetuate some kind of bias what are some things that uh can be done to help mitigate some of these concerns that brings up a great Point love right data that comes in on this side but also on this side is incredibly important into the output that we get when we go to make that prompt and get that answer back so it really is true garbage in and garbage out right so we need to make sure we have good data that comes into the vector database we need to make sure that data is clean governed and managed properly gotcha so what I'm hearing is that things like governance and data management are of course crucial to the vector database right so making sure that the actual information that's flowing through into the model such as the business results in the sample prompt we talked about is governed and clean but also crucially on the large language model side we need to make sure that we're not using a large language model that takes a blackbox approach right so a model where you don't actually know what is the underlying data that went into training it right you don't know if there's any intellectual property in there you don't know if there's inaccurate IES in there or you don't know if there are pieces of data that will end up perpetuating bias in your output results right so as a business and as as a business that's trying to uh uh manage and uphold their brain reputation it's absolutely critical to make sure that we're taking an approach that uh uh uses llms that are transparent in how they were trained and uh we can be 100% certain that there aren't any uh inaccuracies or data that's not supposed to be in there to be in there right yeah exactly it's incredibly important especially as a brand that we get the right answers we've seen the results of impact and especially back to our original question around what was our Revenue in q1 right we don't want that to be impacted by the results of a question that comes from you know that prompts one of our llms exactly exactly so very powerful technology but it makes me think back to the the library uh our journalists and librarian they both trust the data and the books that are in the library we have to have that same kind of confidence when we're building out these types of gender AI use cases for business as well exactly love so governance AI but also data and data management are incredibly important to this process we need all three in order to get the best result",
    "timestamp": "2024-11-23T15:49:06.812035",
    "metadata": {
      "title": "RAG Explained",
      "author": "IBM Technology",
      "length": 483,
      "views": 115468,
      "description": "Get the interactive demo → https://ibm.biz/BdmPEb\nLearn about the technology → https://ibm.biz/BdmPEp\n\nOftentimes, GAI and RAG discussions are interconnected. Learn more about about RAG is and how it works alongside your databases, LLMs and vector databases for better results with Luv Aggarwal and Shawn Brennan. \n\nAI news moves fast. Sign up for a monthly newsletter for AI updates from IBM → https://ibm.biz/BdmP2c",
      "thumbnail_url": "https://i.ytimg.com/vi/qppV3n3YlF8/sddefault.jpg",
      "publish_date": "2024-05-07 05:50:45-07:00"
    }
  },
  {
    "video_id": "qppV3n3YlF8?si=WSsUmp_5ONT0G4DW",
    "title": "RAG Explained",
    "content": "so imagine you're a journalist and you want to write an article on a specific topic now you have a pretty good general idea about this topic but you'd like to do some more research so you go to your local library right now this library has thousands of books on multiple different topics but how do you know as the journalist which books are relevant for your topic well you go to the librarian now the librarian is the expert on what books contain which information in the library so our journalist queries the librarian to uh retrieve uh books on certain topics and the librarian uh produces those books and provides them back to the journalist now the librarian isn't the expert on writing the article and the journalist isn't the expert on finding the most upto-date and relevant information but with the combination of the two we can get the job done love this sounds like a lot like the process of rag or retrieval augmented generation where large language models call on Vector databases to provide key sources of data and information to answer a question H I'm not seeing the connection can you help me understand a little bit better sure so we have a user in your scenario it's that journalist and they have a question so what types of questions would you want to ask right maybe we can make this more of a business context yeah so let's say this is a business analyst and let's say they want to ask um what was Revenue in q1 from customers in the Northeast region right so that's your prompt okay so a couple questions on that user does it have to be a person or could it be something else too yeah so this doesn't necessarily have to be a user it could be a bot or it could be another application even the question that we're talking about what was our Revenue in q1 from the Northeast you know the first part of that question it's pretty easy for you know a general llm to understand right what was our Revenue but it's that second part in q1 from customers in the Northeast that's not something that lln are trained on right it's very specific to our business and it changes over time so we have to treat those separately so how do we how do we uh manage that part of the request exactly you'll need multiple different sources of data potentially to answer a specific question right whether that's maybe a PDF or another business application or maybe some some images whatever that question is we need the appropriate data in order to provide the answer back what technology uh allows us to aggregate that data uh and use it for our llm yeah so we can take this data and we can put it into what we call a vector database a vector database is a mathematical representation of structured and unstructured data similar to what we might see in an array gotcha and and these arrays are uh better suited or easier to understand for machine learning or generative AI models versus just that uh underlying unstructured data exactly we query our Vector database right and we get back an embedding that uh includes uh the the relevant data for which uh we're prompting and then we includeed back into the original prompt right yeah exactly that feeds back into the prompt and then once we're at this point we move over to the other side of the equation which is the large language model gotcha so that that prompt that includes the vector embeddings now are fed into the large language model which then produces the output with the answer to our original question with sourced upto-date and accurate data exactly and that's a crucial aspect of it as new data comes into this Vector database or things that are updated back to your relevant question around performance in q1 as new data comes in those embeddings are updated ated so when that question's asked a second time we have more relevant data in order to provide back to the llm who then generates the output and the answer okay very cool so Sean this sounds a lot like my original analogy there with the librarian and our journalist right so the journalist trusts that the information in the library is accurate and correct now one of the challenges that I see is when I'm talking to Enterprise customers is they're concerned about deploying this kind of techn techology into customer facing business critical applications so if they're building applications taking customer orders processing refunds they're worried that uh uh these kinds of Technologies can produce hallucinations or inaccurate results right or perpetuate some kind of bias what are some things that uh can be done to help mitigate some of these concerns that brings up a great Point love right data that comes in on this side but also on this side is incredibly important into the output that we get when we go to make that prompt and get that answer back so it really is true garbage in and garbage out right so we need to make sure we have good data that comes into the vector database we need to make sure that data is clean governed and managed properly gotcha so what I'm hearing is that things like governance and data management are of course crucial to the vector database right so making sure that the actual information that's flowing through into the model such as the business results in the sample prompt we talked about is governed and clean but also crucially on the large language model side we need to make sure that we're not using a large language model that takes a blackbox approach right so a model where you don't actually know what is the underlying data that went into training it right you don't know if there's any intellectual property in there you don't know if there's inaccurate IES in there or you don't know if there are pieces of data that will end up perpetuating bias in your output results right so as a business and as as a business that's trying to uh uh manage and uphold their brain reputation it's absolutely critical to make sure that we're taking an approach that uh uh uses llms that are transparent in how they were trained and uh we can be 100% certain that there aren't any uh inaccuracies or data that's not supposed to be in there to be in there right yeah exactly it's incredibly important especially as a brand that we get the right answers we've seen the results of impact and especially back to our original question around what was our Revenue in q1 right we don't want that to be impacted by the results of a question that comes from you know that prompts one of our llms exactly exactly so very powerful technology but it makes me think back to the the library uh our journalists and librarian they both trust the data and the books that are in the library we have to have that same kind of confidence when we're building out these types of gender AI use cases for business as well exactly love so governance AI but also data and data management are incredibly important to this process we need all three in order to get the best result",
    "timestamp": "2024-11-23T15:55:24.672324",
    "metadata": {
      "title": "RAG Explained",
      "author": "IBM Technology",
      "length": 483,
      "views": 115469,
      "description": "Get the interactive demo → https://ibm.biz/BdmPEb\nLearn about the technology → https://ibm.biz/BdmPEp\n\nOftentimes, GAI and RAG discussions are interconnected. Learn more about about RAG is and how it works alongside your databases, LLMs and vector databases for better results with Luv Aggarwal and Shawn Brennan. \n\nAI news moves fast. Sign up for a monthly newsletter for AI updates from IBM → https://ibm.biz/BdmP2c",
      "thumbnail_url": "https://i.ytimg.com/vi/qppV3n3YlF8/sddefault.jpg",
      "publish_date": "2024-05-07 05:50:45-07:00"
    }
  },
  {
    "video_id": "T-D1OfcDW1M?si=wFdfNDeOo2-tYDOe",
    "title": "What is Retrieval-Augmented Generation (RAG)?",
    "content": "Large language models. They are everywhere. They get some things amazingly right and other things very interestingly wrong. My name is Marina Danilevsky. I am a Senior Research Scientist here at IBM Research. And I want to tell you about a framework to help large language models be more accurate and more up to date: Retrieval-Augmented Generation, or RAG. Let's just talk about the \"Generation\" part for a minute. So forget the \"Retrieval-Augmented\". So the generation, this refers to large language models, or LLMs, that generate text in response to a user query, referred to as a prompt. These models can have some undesirable behavior. I want to tell you an anecdote to illustrate this. So my kids, they recently asked me this question: \"In our solar system, what planet has the most moons?\" And my response was, “Oh, that's really great that you're asking this question. I loved space when I was your age.” Of course, that was like 30 years ago. But I know this! I read an article and the article said that it was Jupiter and 88 moons. So that's the answer. Now, actually, there's a couple of things wrong with my answer. First of all, I have no source to support what I'm saying. So even though I confidently said “I read an article, I know the answer!”, I'm not sourcing it. I'm giving the answer off the top of my head. And also, I actually haven't kept up with this for awhile, and my answer is out of date. So we have two problems here. One is no source. And the second problem is that I am out of date.   And these, in fact, are two behaviors that are often observed as problematic when interacting with large language models. They’re LLM challenges. Now, what would have happened if I'd taken a beat and first gone and looked up the answer on a reputable source like NASA? Well, then I would have been able to say, “Ah, okay! So the answer is Saturn with 146 moons.” And in fact, this keeps changing because scientists keep on discovering more and more moons. So I have now grounded my answer in something more  believable. I have not hallucinated or made up an answer. Oh, by the way, I didn't leak personal information about how long ago it's been since I was obsessed with space. All right, so what does this have to do with large language models? Well, how would a large language model have answered this question? So let's say that I have a user asking this question about moons. A large language model would confidently say, OK, I have been trained and from what I know in my parameters during my training, the answer is Jupiter. The answer is wrong. But, you know, we don't know. The large language model is very confident in what it answered. Now, what happens when you add this retrieval augmented part here? What does that mean? That means that now, instead of just relying on what the LLM knows, we are adding a content store. This could be open like the internet. This can be closed like some collection of documents, collection of policies, whatever. The point, though, now is that the LLM first goes and talks to the content store and says, “Hey, can you retrieve for me information that is relevant to what the user's query was?” And now, with this retrieval-augmented answer, it's not Jupiter anymore. We know that it is Saturn. What does this look like? Well, first user prompts the LLM with their question. They say, this is what my question was. And originally, if we're just talking to a generative model, the generative model says, “Oh, okay, I know the response. Here it is. Here's my response.”   But now in the RAG framework, the generative model actually has an instruction that says, \"No, no, no.\" \"First, go and retrieve relevant content.\" \"Combine that with the user's question and only then generate the answer.\" So the prompt now has three parts: the instruction to pay attention to, the retrieved content, together with the user's question. Now give a response. And in fact, now you can give evidence for why your response was what it was.   So now hopefully you can see, how does RAG help the two LLM challenges that I had mentioned before?   So first of all, I'll start with the out of date part. Now, instead of having to retrain your model, if new information comes up, like, hey, we found some more moons-- now to Jupiter again, maybe it'll be Saturn again in the future. All you have to do is you augment your data store with new information, update information. So now the next time that a user comes and asks the question, we're ready. We just go ahead and retrieve the most up to date information. The second problem, source. Well, the large language model is now being instructed to pay attention to primary source data before giving its response. And in fact, now being able to give evidence. This makes it less likely to hallucinate or to leak data because it is less likely to rely only on information that it learned during training. It also allows us to get the model to have a behavior that can be very positive, which is knowing when to say, “I don't know.” If the user's question cannot be reliably answered based on your data store, the model should say, \"I don't know,\" instead of making up something that is believable and may mislead the user. This can have a negative effect as well though, because if the retriever is not sufficiently good to give the large language model the best, most high-quality grounding information, then maybe the user's query that is answerable doesn't get an answer. So this is actually why lots of folks, including many of us here at IBM, are working the problem on both sides. We are both working to improve the retriever to give the large language model the best quality data on which to ground its response, and also the generative part so that the LLM can give the richest, best response finally to the user when it generates the answer. Thank you for learning more about RAG and like and subscribe to the channel. Thank you.",
    "timestamp": "2024-11-23T20:04:45.255747",
    "metadata": {
      "title": "What is Retrieval-Augmented Generation (RAG)?",
      "author": "IBM Technology",
      "length": 395,
      "views": 794457,
      "description": "Get hands on RAG training in watsonx.ai→ https://ibm.biz/BdK6UZ\nLearn about the technology → https://ibm.biz/BdMsRT\n\nLarge language models usually give great answers, but because they're limited to the training data used to create the model. Over time they can become incomplete--or worse, generate answers that are just plain wrong. One way of improving the LLM results is called \"retrieval-augmented generation\" or RAG. In this video, IBM Senior Research Scientist Marina Danilevsky explains the LLM/RAG framework and how this combination delivers two big advantages, namely: the model gets the most up-to-date and trustworthy facts, and you can see where the model got its info, lending more credibility to what it generates.\n\nGet weekly AI, cloud, security and sustainability industry news, events and insights. → https://ibm.biz/BdK6UY",
      "thumbnail_url": "https://i.ytimg.com/vi/T-D1OfcDW1M/sddefault.jpg",
      "publish_date": "2023-08-23 04:00:32-07:00"
    }
  }
]